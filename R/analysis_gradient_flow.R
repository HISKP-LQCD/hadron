#' analysis_gradient_flow
#'
#' @param path string. path to data files
#' @param outputbasename string. basename of output files
#' @param basename string. basename of input files, for example "gradflow"
#' @param read.data boolean. Indicates whether to read data fresh from
#'   data files or to use `basename.raw.gradflow.Rdata` lying in the 
#'   present working directory instead
#' @param pl boolean. If set to `TRUE` plots will be generated
#' @param skip integer. number of measurements to skip
#' @param start integer. start value for MD time, this affects the MD time
#'   indicated in the plots
#' @param scale numeric. scale factor for the MD time, should be set to
#'   the stridelength (in units of trajectories or configurations)
#'   which was used to produce the gradient flow files, such that
#'   the distance between measurements can be interpreted
#'   correctly and the reported autocorrelation times scaled appropriately.
#' @param plotsize numeric. Plot sidelength, this is passed to
#'   \code{tikz.init}.
#' @param dbg boolean. If set to `TRUE` debugging output will be provided.
#'
#' @description
#' function to analyse the gradient flow output files generated by
#' the tmLQCD software, see references.
#' 
#' The function generates a number of output files beyond plots, much like
#' \link{analysis_online}. In these, the following correspondences of variable
#' names to observables hold:
#'
#' \itemize{
#'   \item{traj: }{Configuration or trajectory number.}
#'   \item{t: }{Gradient flow time \eqn{t}.}
#'   \item{P: }{Average plaquette \eqn{<P>}.}
#'   \item{Eplaq: }{Energy density \eqn{E(t)} in the plaquette definition.}
#'   \item{Esym: }{Energy density \eqn{E(t)} in the clover definition.}
#'   \item{tsqEplaq: }{The observable \eqn{t^2 E(t)} used to define the scale \eqn{t_0} in the plaquette definition.}
#'   \item{tsqEsym: }{The observable \eqn{t^2 E(t)} used to define the scale \eqn{t_0} in the clover definition.}
#'   \item{Wsym: }{The observable \eqn{t d/dt (t^2 E(t))} used to define the scale \eqn{w_0} in the clover definition.}
#'   \item{Qsym: }{The topological charge \eqn{Q(t)} in the clover definition.}
#' }
#' 
#' The observables are analysed using the Gamma method (\link{uwerr}) and
#' the gradient flow scales \eqn{t_0} and \eqn{w_0} are determined.
#'
#' The generated files are:
#' \itemize{
#'   \item{gradflow.summary.Rdata: }{Named list of data frames \code{gradflow_resultsum}.
#'         The names of the elements in this list  are based on \code{outputbasename}.
#'         The function attempts to read this file from the present working directory,
#'         so as to add to the list. If the file does not exist, it is created.
#'         If a name already exists in the list, it is overwritten. Each element
#'         contains the central value, statistical errors in positive and negative directions and
#'         the integrated autocorrelation time and its error for the observables "tsqEplaq", "tsqEsym"
#'         , "Wsym" and "Qsym_maxft", where the last corresponds to the topological
#'         charge at maximal flow time.}
#'   \item{%s.raw.gradflow.Rdata: }{The raw data read from the gradient flow files is written
#'         to this file with the pattern replaced by \code{outputbasename}. All of the observables
#'         listed above are written for all trajctories and flow times.}
#'   \item{%s.result.gradflow.Rdata: }{The results of the Gamma method analysis are written
#'         into this file with the pattern replaced by \code{outputbasename}. The saved object
#'         , \code{gradflow}, is a data frame with a column "t" and columns of the form
#'         "x.y", where "x" is the observable name as given in the list above and "y" is one
#'         of "value", "dvalue", "ddvalue", "tauint" and "dttauint". See \link{uwerr} for the meaning
#'         of each of these.}
#'   \item{%s.gradflow_results_per_meas.Rdata: }{Rather than performing the Gamma method analysis directly
#'         at each flow time, it is also possible to determine the gradient flow scales
#'         for each measurement and to extract the topological charge at the maximum flow time.
#'         The object \code{gradflow_results_per_meas} in this file, where the pattern is replaced
#'         with \code{outputbasename}, contains the results of this procedure as a data frame
#'         with the columns "traj", "tsqEplaq_per_meas", "tsqEsym_per_meas", "Wsym_per_meas" 
#'         and "Qsym_maxft_per_meas". Note: the object is a \link{tibble}.}
#' }
#'
#' @references
#' K. Jansen and C. Urbach, Comput.Phys.Commun. 180 (2009) 2717-2738

#' @return
#' Nothing is returned.
#'
#' @export
analysis_gradient_flow <- function(path, outputbasename, basename="gradflow",
                                   read.data=TRUE, pl=FALSE, plotsize=4,
                                   skip=0, start=0,
                                   scale=1, dbg=FALSE) {

  dplyr_version_required <- "1.0.0"
  dplyr_avail <- requireNamespace("dplyr", versionCheck = list(op = ">=", version = dplyr_version_required))
  if( !dplyr_avail ){
    stop(sprintf("The 'dplyr' package in version >= %s is required to use this function!\n",
                 dplyr_version_required))
  }

  # much like for the analysis of online measurements, we store summary information
  # in the list "gradflow_resultsum" with elements named by "outputbasename"
  # such that when the analysis is rerun, the entries are replaced
  resultsfile <- "gradflow.summary.Rdata"
  gradflow_resultsum <- list()
  if(file.exists(resultsfile)){
    message("Loading gradient flow results database from ", resultsfile, "\n")
    load(resultsfile)
  }

  if(read.data) {
    raw.gradflow <- readgradflow(path=path, skip=skip, basename=basename)
    save(raw.gradflow,file=sprintf("%s.raw.gradflow.Rdata",outputbasename),compress=FALSE)
  }else{
    warning(sprintf("Warning, reading data from %s.raw.gradflow.Rdata, if the number of samples changed, set read.data=TRUE to reread all output files\n",outputbasename))
    load(sprintf("%s.raw.gradflow.Rdata",outputbasename))
  }
  if(dbg==TRUE) print(raw.gradflow)

  t_vec <- unique(raw.gradflow$t)
  Ncol <- ncol(raw.gradflow)
  Nrow <- length(t_vec)
  cnames <- colnames(raw.gradflow[,3:Ncol])

  have_Qsym <- "Qsym" %in% cnames

  # allocate some memory, for each observable, have space for the value, the error and the autocorrelation time
  # create a list with NULL rownams and sensible column names for this purpose
  subnames <- c("value","dvalue","ddvalue","tauint","dtauint")
  outer.cnames <- t(outer(cnames,subnames,FUN=function(x,y) { paste(x,y,sep=".") }))
  grad.dimnames <- list()
  grad.dimnames[[1]] <- NULL
  grad.dimnames[[2]] <- c("t",as.vector(outer.cnames) )
  
  gradflow <- as.data.frame(matrix(data=NA,nrow=Nrow,ncol=(length(subnames)*(Ncol-2)+1),dimnames=grad.dimnames))
  for(i_row in 1:length(t_vec)){
    uwerr.gradflow <- apply(X=raw.gradflow[which(raw.gradflow$t==t_vec[i_row]),3:Ncol],MARGIN=2,FUN=uwerrprimary)
    summaryvec <- c(t_vec[i_row])
    for(i_col in 1:length(cnames)) {
      obs <- uwerr.gradflow[[cnames[i_col]]]
      # we apply the 'scale' factor to the integrated autocorrelation time
      # in order to obtain it in the right units
      summaryvec <- c(summaryvec, obs$value, obs$dvalue, obs$ddvalue, obs$tauint*scale, obs$dtauint*scale)
    }
    gradflow[i_row,] <- summaryvec
  }
  save(gradflow,file=sprintf("%s.result.gradflow.Rdata",outputbasename),compress=FALSE)
 
  gf_scales <- list()
  gf_latspacs <- list()
  gf_approx_scales <- list()
  gradflow_resultsum[[outputbasename]] <- NULL
  for( i in 1:length(ref_gf_scales) ){
    # extract colum names of gradflow relevant to the observable currently in the loop
    nms <- c("t",
             outer(ref_gf_scales[[i]]$obs, subnames, FUN=function(x,y){ paste(x,y,sep=".") })
             )

    val <- gradflow[,sprintf("%s.value", ref_gf_scales[[i]]$obs)]
    dval <- gradflow[,sprintf("%s.dvalue", ref_gf_scales[[i]]$obs)] 
    gf_scales[[i]] <- c(approx( x=val+dval,y=gradflow$t,xout=0.3)$y, 
                        approx( x=val, y=gradflow$t, xout=0.3 )$y, 
                        approx( x=val-dval, y=gradflow$t, xout=0.3)$y )

    ## determine which discrete value of t is closest to the scale in question
    for( tidx in 1:length(t_vec) ){
      if( t_vec[tidx] >= gf_scales[[i]][2] ){
        gf_approx_scales[[i]] <- gradflow[tidx,nms]
        colnames(gf_approx_scales[[i]]) <-  c("t", subnames)
        break
      }
    }

    ## summary information about the gradient flow scales:
    ## observable name, value, stat. errors in + and - directions
    ## we also add the autocorrelation time and error of the observable
    ## at the value of t closest to our scale
    gradflow_resultsum[[outputbasename]] <- 
      rbind(gradflow_resultsum[[outputbasename]],
            data.frame(obs=ref_gf_scales[[i]]$obs,
                       val=gf_scales[[i]][2],
                       pdval=gf_scales[[i]][2]-gf_scales[[i]][1],
                       mdval=gf_scales[[i]][3]-gf_scales[[i]][2],
                       tauint=gf_approx_scales[[i]]$tauint,
                       dtauint=gf_approx_scales[[i]]$dtauint
                       )
            )

    # sqrt of our bounds to compute the lattice spacing
    sqrt_gf_scale <- sqrt(gf_scales[[i]])

    gf_latspacs[[i]] <- list()
    for( k in 1:length(sqrt_gf_scale) ){
      gf_latspacs[[i]][[k]] <- compute_ratio(dividend=ref_gf_scales[[i]],
                                             # note that we use zero error on our scale
                                             # as the error on the reference scale is large enough
                                             divisor=list(val=sqrt_gf_scale[k],
                                                          dval=0))
    }
  }

  #### GF SCALE RATIOS ###


  Wsym_idx <- which(gradflow_resultsum[[outputbasename]]$obs == "Wsym")
  for( t0type in c("plaq", "sym") ){
    tsqE <- sprintf("tsqE%s", t0type)
    t0lab <- sprintf("t0%s", t0type)
    ratiolab <- sprintf("%s_ov_w0", t0lab)
    tsqE_idx <- which(gradflow_resultsum[[outputbasename]]$obs == tsqE)
    
    # we don't want to bootstrap absolutely everything so we limit ourselves to the most relevant region
    # and only the observables of interest 
    trange <- range(gradflow_resultsum[[outputbasename]]$val[ which(gradflow_resultsum[[outputbasename]]$obs == tsqE) ],
                    gradflow_resultsum[[outputbasename]]$val[ which(gradflow_resultsum[[outputbasename]]$obs == "Wsym") ])
    trange <- c(trange[1]*0.5, trange[2]*1.5)
    gf_tseries <- subset(tseries_orig(data = dplyr::filter(dplyr::rename(raw.gradflow, md_idx = traj),
                                                           t >= trange[1] & t <= trange[2]),
                                      explanatory_vars = c("t")),
                         subset = c(tsqE, "Wsym"))

    boot.l <- 2*ceiling(max(gradflow_resultsum[[outputbasename]]$tauint[Wsym_idx],
                            gradflow_resultsum[[outputbasename]]$tauint[tsqE_idx]))
    boot.R <- 3*length(unique(raw.gradflow$traj))

    gf_tseries_boot <- bootstrap.tseries(gf_tseries,
                                         boot.R = boot.R,
                                         boot.l = boot.l,
                                         sim = 'geom',
                                         endcorr = TRUE,
                                         seed = 12345,
                                         serial = FALSE)

    plan <- list()
    plan[["t0"]] <- parse(text = sprintf("approx(x = %s, y = t, xout = 0.3)$y", tsqE) )
    plan[["w0"]] <- expression( sqrt(approx(x = Wsym, y = t, xout = 0.3)$y) )

    gf_scales <- apply_reduce_plan.tseries(ts = gf_tseries_boot, reduce_vars = c("t"), plan = plan)

    ## now actually compute the ratio
    plan <- list()
    plan[["t0_ov_w0"]] <- parse(text = sprintf("t0 / w0", t0lab) )
    gf_scale_ratio <- apply_transmute_plan.tseries(ts = gf_scales, plan = plan)

    
    gradflow_resultsum[[outputbasename]] <-
      rbind(gradflow_resultsum[[outputbasename]],
            data.frame(obs = ratiolab,
                       val = gf_scale_ratio$central$t0_ov_w0,
                       pdval = gf_scale_ratio$se$t0_ov_w0,
                       mdval = gf_scale_ratio$se$t0_ov_w0,
                       # since we're working from bootstrap samples, we don't calculate
                       # the autocorrelation times here 
                       tauint = NA,
                       dtauint = NA
                      )
            )
  }

  if( have_Qsym ){
    n <- length(gradflow$t)
    gradflow_resultsum[[outputbasename]] <-
      rbind(gradflow_resultsum[[outputbasename]],
            data.frame(obs = "Qsym_maxft",
                       val = gradflow$Qsym.value[n],
                       pdval = gradflow$Qsym.dvalue[n],
                       mdval = gradflow$Qsym.dvalue[n],
                       # scale factor has already been applied above! 
                       tauint = gradflow$Qsym.tauint[n],
                       dtauint = gradflow$Qsym.dtauint[n]
                       )
            )
  }
  save(gradflow_resultsum, file=resultsfile)
   
  if(pl) {
    tikzfiles <- tikz.init(basename=sprintf("%s.gradflow",outputbasename),width=plotsize,height=plotsize)
    for( i in 1:length(ref_gf_scales) ){
      scale_obs <- ref_gf_scales[[i]]$obs
      scale_obslabel <- ref_gf_scales[[i]]$obslabel
      scale_label <- ref_gf_scales[[i]]$label

      val <- gradflow[,sprintf("%s.value", scale_obs)]
      dval <- gradflow[,sprintf("%s.dvalue", scale_obs)]

      gf_scale <- gf_scales[[i]]
      gf_latspac <- gf_latspacs[[i]]

      # set up plot
      # xlim is set to 1.25 times the value of t corresponding to the upper
      # limit of the reference scale in lattice units
      plot(x=gradflow$t, 
           y=val,
           type='n',
           xlim=c(0,1.25*gf_scale[1]),
           ylim=c(0.0,0.4),
           xlab="$t/a^2$",
           ylab=scale_obslabel,
           las=1)
      # draw errorband
      poly.col <- rgb(red=1.0,green=0.0,blue=0.0,alpha=0.6)
      poly.x <- c(gradflow$t,rev(gradflow$t))
      poly.y <- c(val+dval,rev(val-dval))
      polygon(x=poly.x,y=poly.y,col=poly.col)
      abline(h=0.3)
      abline(v=gf_scale)
      lines(x=gradflow$t, y=val)
      legend(x="topleft",
             legend=c(sprintf("$%s = %s$",
                              scale_label,
                              tex.catwitherror(x=gf_scale[2],
                                               # for the error, we use the average of the plus and minus errors
                                               dx=0.5*(abs(gf_scale[3]-gf_scale[2]) + abs(gf_scale[2]-gf_scale[1])),
                                               digits=2,
                                               with.dollar=FALSE, with.cdot=FALSE)
                              ),
                    sprintf("$a \\sim %s$\\,fm ($N_f = 2+1$)", 
                            tex.catwitherror(x=gf_latspac[[2]]$val,
                                             dx=sqrt( (0.5* ( 
                                                             abs( gf_latspac[[3]]$val-gf_latspac[[2]]$val) +
                                                             abs( gf_latspac[[1]]$val-gf_latspac[[2]]$val) 
                                                             ) 
                                                       )^2 + gf_latspac[[2]]$dval^2 ),
                                             digits=2,
                                             with.dollar=FALSE, with.cdot=FALSE)
                            )
                    ),
             bty='n')
      
      ### plot MD history of the scale observable
      scale_obs_per_meas <- dplyr::pull(gradflow_results_per_meas, paste(scale_obs, "_per_meas", sep = "") )
      tseries <- data.frame(y = scale_obs_per_meas,
                            t = start + c( skip :(skip + 
                                                  length(scale_obs_per_meas) - 1) )*scale )
      scale_obs_uwerr <- plot_timeseries(dat=tseries,
                                         ylab=sprintf("$%s$", scale_label),
                                         titletext="")

      # indicate integrated autocorrelation time in scaled units
      legend(x="topleft",
             bty='n',
             pch=NA,
             legend=sprintf("$\\tau_{\\mathrm{int}}( %s ) = %s$ traj.",
                            scale_label,
                            tex.catwitherror(x=scale_obs_uwerr["tauint",1] * scale,
                                             dx=scale_obs_uwerr["dtauint",1] * scale,
                                             digits=1,
                                             with.dollar=FALSE, with.cdot=FALSE)
                            )
             )
    }
   
    if( have_Qsym ){
      ################ TOPOLOGICAL CHARGE ####################
      # set up plot
      plot(x=gradflow$t, 
           y=gradflow$Qsym.value,
           type='n',
           ylim=range(c(gradflow$Qsym.value+gradflow$Qsym.dvalue, gradflow$Qsym.value-gradflow$Qsym.dvalue)),
           xlim=c(0.01,max(gradflow$t)),
           xlab="$t/a^2$",
           ylab="$Q(t)$",
           las=1,
           log='x')
      # draw errorband
      poly.col <- rgb(red=1.0,green=0.0,blue=0.0,alpha=0.6)
      poly.x <- c(gradflow$t,rev(gradflow$t))
      poly.y <- c(gradflow$Qsym.value+gradflow$Qsym.dvalue,rev(gradflow$Qsym.value-gradflow$Qsym.dvalue))
      polygon(x=poly.x,y=poly.y,col=poly.col)
      lines(x=gradflow$t, y=gradflow$Qsym.value)
      
      # plot MD history of Q at maximal flow time
      tmax_md_idx <- which(raw.gradflow$t==max(raw.gradflow$t))
      tmax_idx <- which(gradflow$t==max(gradflow$t))
      tseries <- data.frame(y=raw.gradflow[tmax_md_idx,"Qsym"],
                            t=start + c( skip :( skip + length(raw.gradflow[tmax_md_idx,"Qsym"]) - 1 ) )*scale)
      plot_timeseries(dat=tseries,
                      ylab=sprintf("$Q\\left( t/a^2 = %.2f \\right)$",max(raw.gradflow$t)),
                      titletext="")

      # indicate integrated autocorrelation time in scaled units
      legend(x="topleft",
             bty='n',
             pch=NA,
             legend=sprintf("$\\tau_{\\mathrm{int}}($ %s $) = %s$ traj.",
                            sprintf("$Q\\left( t/a^2 = %.2f \\right)$",max(raw.gradflow$t)),
                            tex.catwitherror(x=gradflow[tmax_idx, "Qsym.tauint"],
                                             dx=gradflow[tmax_idx, "Qsym.dtauint"],
                                             digits=1,
                                             with.dollar=FALSE, with.cdot=FALSE)
                            )
             )
    } # if( have_Qsym )
    
    tikz.finalize(tikzfiles)
  } # if(pl)
}


